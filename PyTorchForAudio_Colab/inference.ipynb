{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"inference.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyN780ikSaKwHrxF4G2JjJvO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nCL9C3XbR50v","executionInfo":{"status":"ok","timestamp":1628341141062,"user_tz":-60,"elapsed":35057,"user":{"displayName":"Edward Hulme","photoUrl":"","userId":"12267249823946796482"}},"outputId":"f6a14654-bf3d-403a-dd36-7d1e404d17e4"},"source":["# Load the Drive helper and mount\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WhxttPaASO6G","executionInfo":{"status":"ok","timestamp":1628341153440,"user_tz":-60,"elapsed":3926,"user":{"displayName":"Edward Hulme","photoUrl":"","userId":"12267249823946796482"}},"outputId":"74773edb-bd0f-4f62-8158-49331e0d14f9"},"source":["!pip install torchaudio"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting torchaudio\n","  Downloading torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 5.3 MB/s \n","\u001b[?25hRequirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (from torchaudio) (1.9.0+cu102)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchaudio) (3.7.4.3)\n","Installing collected packages: torchaudio\n","Successfully installed torchaudio-0.9.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"h9R55NzPSRwG","executionInfo":{"status":"ok","timestamp":1628341157258,"user_tz":-60,"elapsed":423,"user":{"displayName":"Edward Hulme","photoUrl":"","userId":"12267249823946796482"}}},"source":["import sys\n","sys.path.insert(0,'/content/drive/My Drive/PyTorchForAudio_Colab/')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"1px9D6i-RzPA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628341577508,"user_tz":-60,"elapsed":177,"user":{"displayName":"Edward Hulme","photoUrl":"","userId":"12267249823946796482"}},"outputId":"9b7ad054-4490-416e-dfc5-e41f06fdb11c"},"source":["import torch\n","import torchaudio\n","\n","from urbansounddatasetcpu import UrbanSoundDataset\n","from cnn import CNNNetwork\n","from train import AUDIO_DIR, ANNOTATIONS_FILE, SAMPLE_RATE, NUM_SAMPLES\n","\n","\n","class_mapping = [\n","    \"air_conditioner\",\n","    \"car_horn\",\n","    \"children_playing\",\n","    \"dog_bark\",\n","    \"drilling\",\n","    \"engine_idling\",\n","    \"gun_shot\",\n","    \"jackhammer\",\n","    \"siren\",\n","    \"street_music\"\n","]\n","\n","\n","def predict(model, input, target, class_mapping):\n","    model.eval()\n","    with torch.no_grad():\n","        predictions = model(input)\n","        # Tensor (1, 10) -> [ [0.1, 0.01, ..., 0.6] ]\n","        predicted_index = predictions[0].argmax(0)\n","        predicted = class_mapping[predicted_index]\n","        expected = class_mapping[target]\n","    return predicted, expected\n","\n","\n","if __name__ == \"__main__\":\n","    # load back the model\n","    cnn = CNNNetwork()\n","    state_dict = torch.load(\"/content/drive/My Drive/PyTorchForAudio_Colab/cnnnet.pth\", map_location=\"cpu\")\n","    cnn.load_state_dict(state_dict)\n","\n","    # load urban sound dataset dataset\n","    mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n","        sample_rate=SAMPLE_RATE,\n","        n_fft=1024,\n","        hop_length=512,\n","        n_mels=64\n","    )\n","\n","    usd = UrbanSoundDataset(ANNOTATIONS_FILE,\n","                            AUDIO_DIR,\n","                            mel_spectrogram,\n","                            SAMPLE_RATE,\n","                            NUM_SAMPLES,\n","                            \"cpu\")\n","\n","\n","    # get a sample from the urban sound dataset for inference\n","    input, target = usd[0][0], usd[0][1] # [batch size, num_channels, fr, time]\n","    input.unsqueeze_(0)\n","\n","    # make an inference\n","    predicted, expected = predict(cnn, input, target,\n","                                  class_mapping)\n","    print(f\"Predicted: '{predicted}', expected: '{expected}'\")\n"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Predicted: 'dog_bark', expected: 'dog_bark'\n"],"name":"stdout"}]}]}